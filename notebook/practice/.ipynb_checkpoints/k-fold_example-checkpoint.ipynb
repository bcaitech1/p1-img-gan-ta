{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(26 * 26 * 10, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k_folds = 5\n",
    "# num_epochs = 1\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "  \n",
    "# results = {}\n",
    "  \n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# dataset_train_part = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=True)\n",
    "# dataset_test_part = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=False)\n",
    "# dataset = ConcatDataset([dataset_train_part, dataset_test_part])\n",
    "  \n",
    "\n",
    "# kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    \n",
    "#     train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "#     test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "#     trainloader = torch.utils.data.DataLoader(\n",
    "#                       dataset, \n",
    "#                       batch_size=10, sampler=train_subsampler)\n",
    "#     testloader = torch.utils.data.DataLoader(\n",
    "#                       dataset,\n",
    "#                       batch_size=10, sampler=test_subsampler)\n",
    "    \n",
    "#     network = SimpleConvNet()\n",
    "#     network.apply(reset_weights)\n",
    "    \n",
    "#     optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "    \n",
    "#     for epoch in range(0, num_epochs):\n",
    "        \n",
    "#         current_loss = 0.0\n",
    "        \n",
    "#         for i, data in enumerate(trainloader, 0):\n",
    "#             inputs, targets = data\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             outputs = network(inputs)\n",
    "            \n",
    "#             loss = loss_function(outputs, targets)\n",
    "            \n",
    "#             loss.backward()\n",
    "        \n",
    "#             optimizer.step()\n",
    "#             current_loss += loss.item()\n",
    "#             if i % 500 == 499:\n",
    "#                 print('Loss after mini-batch %5d: %.3f' %\n",
    "#                       (i + 1, current_loss / 500))\n",
    "#                 current_loss = 0.0\n",
    "                \n",
    "#     print('Training process has finished. Saving trained model.')\n",
    "\n",
    "#     print('Starting testing')\n",
    "    \n",
    "#     save_path = f'./model-fold-{fold}.pth'\n",
    "#     torch.save(network.state_dict(), save_path)\n",
    "\n",
    "#     correct, total = 0, 0\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         for i, data in enumerate(testloader, 0):\n",
    "            \n",
    "#             inputs, targets = data\n",
    "            \n",
    "#             outputs = network(inputs)\n",
    "            \n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += targets.size(0)\n",
    "#             correct += (predicted == targets).sum().item()\n",
    "            \n",
    "#     print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "#     print('--------------------------------')\n",
    "#     results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "#     print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "#     print('--------------------------------')\n",
    "#     sum = 0.0\n",
    "#     for key, value in results.items():\n",
    "#         print(f'Fold {key}: {value} %')\n",
    "#         sum += value\n",
    "#     print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def get_label(self, img_path):\n",
    "        search = img_path.split(\"/\")\n",
    "        mask_check = search[-1].split(\".\")[0]\n",
    "        age_check = int(search[-2].split(\"_\")[-1])\n",
    "        gender_check = search[-2].split(\"_\")[-3]\n",
    "        label = -1\n",
    "        \n",
    "        if mask_check ==  \"normal\":\n",
    "            if gender_check == \"male\":\n",
    "                if age_check < 30:\n",
    "                    label = 12\n",
    "                elif 30 <= age_check < 60:\n",
    "                    label = 13\n",
    "                else:\n",
    "                    label = 14\n",
    "            elif gender_check == \"female\":\n",
    "                if age_check < 30:\n",
    "                    label = 15\n",
    "                elif 30 <= age_check < 60:\n",
    "                    label = 16\n",
    "                else:\n",
    "                    label = 17\n",
    "        elif mask_check == \"incorret_mask\":\n",
    "            if gender_check == \"male\":\n",
    "                if age_check < 30:\n",
    "                    label = 6\n",
    "                elif 30 <= age_check < 60:\n",
    "                    label = 7\n",
    "                else:\n",
    "                    label = 8  \n",
    "            elif gender_check == \"female\":\n",
    "                if age_check < 30:\n",
    "                    label = 9\n",
    "                elif 30 <= age_check < 60:\n",
    "                    label = 10\n",
    "                else:\n",
    "                    label = 11\n",
    "        else:\n",
    "            if gender_check == \"male\":\n",
    "                if age_check < 30:\n",
    "                    label = 0\n",
    "                elif 30 <= age_check < 60:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 2  \n",
    "            elif gender_check == \"female\":\n",
    "                if age_check < 30:\n",
    "                    label = 3\n",
    "                elif 30 <= age_check < 60:\n",
    "                    label = 4\n",
    "                else:\n",
    "                    label = 5\n",
    "        return label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        \n",
    "        label = self.get_label(self.img_paths[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(label)\n",
    "        return label, image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 transform지정\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.CenterCrop(300),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data setting\n",
    "# train\n",
    "train_df = pd.read_csv(os.path.join(train_dir, 'train.csv'))\n",
    "train_image_dir = os.path.join(train_dir, 'images')\n",
    "\n",
    "train_image_paths = []\n",
    "for path in train_df[\"path\"]:\n",
    "    middle_path = os.path.join(train_image_dir, path)\n",
    "    for file_name in os.listdir(middle_path):\n",
    "        if file_name.startswith(\".\"):\n",
    "            continue\n",
    "        train_image_paths.append(os.path.join(middle_path, file_name))\n",
    "        \n",
    "train_dataset = TrainDataset(train_image_paths, transform)\n",
    "train_loader  =  DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 32,\n",
    "    shuffle=True,\n",
    "    num_workers = 4,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(train_dataset)):\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      train_dataset, \n",
    "                      batch_size=10, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      train_dataset,\n",
    "                      batch_size=10, sampler=test_subsampler)\n",
    "    print(\"fold : \", fold)\n",
    "    print(\"train :\", len(trainloader))\n",
    "    print(\"test : \", len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/opt/ml/pstage01')\n",
    "from model import models, loss, metric\n",
    "from dataloader import mask\n",
    "from util import meter, transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train'\n",
    "img_dir = f'{data_dir}/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB mean, std\n",
    "mean, std = (0.56019358, 0.52410121, 0.501457), (0.23318603, 0.24300033, 0.24567522)\n",
    "\n",
    "transform = transformers.get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = mask.MaskBaseDataset(\n",
    "    \n",
    "    img_dir=img_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_val = len(dataset)\n",
    "# n_train = len(dataset) - n_val\n",
    "# train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# # 각 dataset에 augmentation 함수를 설정합니다.\n",
    "# train_dataset.dataset.set_transform(transform['train'])\n",
    "# val_dataset.dataset.set_transform(transform['val'])\n",
    "\n",
    "train_dataset = TrainDataset(train_image_paths, transform)\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=10, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=10, sampler=test_subsampler)\n",
    "    print(\"fold : \", fold)\n",
    "    print(\"train :\", len(trainloader))\n",
    "    print(\"test : \", len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
