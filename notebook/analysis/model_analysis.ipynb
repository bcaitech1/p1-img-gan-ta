{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.transforms import Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/opt/ml/pstage01')\n",
    "from model import models,loss, metric\n",
    "from dataloader import mask\n",
    "from util import meter, transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir = '/opt/ml/input/data/train'\n",
    "img_dir = f'{data_dir}/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = (0.56019358, 0.52410121, 0.501457), (0.23318603, 0.24300033, 0.24567522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mask.MaskBaseDataset(data_dir = data_dir,img_dir=img_dir)\n",
    "num_classes = 18\n",
    "\n",
    "transform = transformers.get_transforms(mean=mean, std=std, transform_type = 'basic')\n",
    "dataset.set_transform(transform['val'])\n",
    "\n",
    "# -- data_loader\n",
    "_, val_set = dataset.split_dataset()\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_set,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    batch_size=32,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_2d_to_1d(tensor_2d):\n",
    "    \"\"\"\n",
    "    tensor의 shape를 2차원이면 1차원으로 바꿔줌\n",
    "    \"\"\"\n",
    "    if len(tensor_2d.shape) == 2:\n",
    "        tensor_2d = tensor_2d.reshape(-1)\n",
    "    return tensor_2d\n",
    "\n",
    "\n",
    "def tensor_images_to_numpy_images(images, renormalize=False):\n",
    "    \"\"\"\n",
    "    이미지 화소 되돌리기 작업\n",
    "    \"\"\"\n",
    "    images = images.detach().cpu().numpy()\n",
    "#     print(images.shape)\n",
    "    if renormalize:\n",
    "        images = np.clip((images * STD) + MEAN, 0, 1)\n",
    "    images = images.transpose(0, 2, 3, 1)\n",
    "#     print(images.shape)\n",
    "    return images\n",
    "\n",
    "\n",
    "def tensor_to_numpy(tensors):\n",
    "    \"\"\"\n",
    "    tensor에서 numpt array로 바꿔줌\n",
    "    \"\"\"\n",
    "    return tensors.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_datas(model, device, dataloader, argmax=True):\n",
    "    \"\"\"\n",
    "    image데이터와 이에 대한 실제 라벨값과 에측 라벨값에 대한 정보를 반환\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_images = torch.tensor([]).to(device)\n",
    "    all_labels = torch.tensor([]).to(device)\n",
    "    all_preds = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels, _) in enumerate(tqdm(dataloader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            preds = model(images)\n",
    "            if argmax:\n",
    "                preds = torch.argmax(preds, dim=1)\n",
    "                preds = change_2d_to_1d(preds)\n",
    "\n",
    "            all_images = torch.cat((all_images, images))\n",
    "            all_labels = torch.cat((all_labels, labels))\n",
    "            all_preds = torch.cat((all_preds, preds))\n",
    "            \n",
    "\n",
    "    return all_images, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/opt/ml/model_save/04_04_v3/004_loss_7.5e-05_acc_0.97.ckpt\"\n",
    "model = models.MyResNext()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.cuda()\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨값을 가져옴\n",
    "images, labels, preds = get_all_datas(model, device, val_loader, argmax=False)\n",
    "print(images.shape, labels.shape, preds.shape)\n",
    "labels, preds = tensor_to_numpy(labels), tensor_to_numpy(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "def log_f1_and_acc_scores(labels, preds, num_classes):\n",
    "    # class 별 f1_score를 계산\n",
    "\n",
    "    summary_table = pd.DataFrame([])\n",
    "    false_table = pd.DataFrame([])\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        fancy_idx = np.where(labels == class_idx) # labels에서 현재 클래스에 대한 인덱스만 뽑아옴\n",
    "\n",
    "        binary_labels = labels[fancy_idx] == class_idx\n",
    "        binary_outputs = preds[fancy_idx] == class_idx\n",
    "#         print(labels[fancy_idx])\n",
    "#         print(labels[fancy_idx] == class_idx)\n",
    "#         print(preds[fancy_idx])\n",
    "#         print(preds[fancy_idx] == class_idx)\n",
    "        false_count = len(binary_outputs[binary_outputs == False])\n",
    "\n",
    "        f1 = f1_score(binary_labels, binary_outputs, average=\"binary\")\n",
    "        pr = precision_score(binary_labels, binary_outputs, average=\"binary\")\n",
    "        re = recall_score(binary_labels, binary_outputs, average=\"binary\")\n",
    "        acc = accuracy_score(binary_labels, binary_outputs)\n",
    "\n",
    "        summary_table.loc[\"1003\", f\"{class_idx} f1\"] = f1\n",
    "        summary_table.loc[\"1003\", f\"{class_idx} pr\"] = pr\n",
    "        summary_table.loc[\"1003\", f\"{class_idx} re\"] = re\n",
    "        summary_table.loc[\"1003\", f\"{class_idx} acc\"] = acc\n",
    "        \n",
    "        false_table.loc[f\"{class_idx}\",\"false count\"] = false_count\n",
    "    \n",
    "    summary_table.fillna(0, inplace=True)\n",
    "    summary_table = summary_table.applymap(lambda x: \"{:,.1f}%\".format(x * 100))\n",
    "    \n",
    "    return summary_table, false_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df, false_df = log_f1_and_acc_scores(labels, np.argmax(preds, axis=1), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def log_confusion_matrix(labels, preds, num_classes):\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(18, 9))\n",
    "    fig.suptitle(\"Confusion Matrix\", fontsize=16)\n",
    "    cmap = plt.cm.GnBu\n",
    "    \n",
    "    # confusion matrix 구하기\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    \n",
    "    axes[0].imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "\n",
    "    axes[0].set_xticks(range(num_classes))\n",
    "    axes[0].set_yticks(range(num_classes))\n",
    "    axes[0].set_ylabel(\"True label\")\n",
    "    axes[0].set_xlabel(\"Predicted label\")\n",
    "    \n",
    "    thresh = cm.max() / 2.0\n",
    "    \n",
    "    # 갯수 세주기\n",
    "    # 대각선에 많을수록 많이 맞추는 것\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        axes[0].text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "        \n",
    "    #못마추는 것만 뽑아내기\n",
    "    np.fill_diagonal(cm, 0)\n",
    "    axes[1].imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "\n",
    "    axes[1].set_xticks(range(num_classes))\n",
    "    axes[1].set_yticks(range(num_classes))\n",
    "    axes[0].set_ylabel(\"True label\")\n",
    "    axes[1].set_xlabel(\"Predicted label\")\n",
    "\n",
    "    thresh = cm.max() / 2.0\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        axes[1].text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = log_confusion_matrix(labels, np.argmax(preds, axis=1), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값이 어떻게 떨어지는가 보기\n",
    "from scipy.special import softmax\n",
    "\n",
    "MEAN = np.array([0.548, 0.504, 0.479]).reshape(-1, 1, 1)\n",
    "STD = np.array([0.237, 0.247, 0.246]).reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images = tensor_images_to_numpy_images(images, renormalize=True)\n",
    "labels = labels.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_information = []\n",
    "\n",
    "for i in range(len(np_images)):\n",
    "    search_information.append((np_images[i], labels[i], preds[i]))\n",
    "\n",
    "search_information_iter = iter(search_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_plots_image(ax, image, pred, pred_label, true_label, num_classes):\n",
    "    ax.grid(False)\n",
    "    color = \"blue\" if pred_label == true_label else \"red\"\n",
    "    \n",
    "    classes = np.array([str(i) for i in range(num_classes)])\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.set_xlabel(\n",
    "        \"pred: {} {:2.0f}% | (true: {})\".format(\n",
    "            classes[pred_label], 100 * pred[pred_label], classes[true_label]\n",
    "        ),\n",
    "        color=color,\n",
    "        fontsize=18\n",
    "    )\n",
    "\n",
    "def _log_plots_distribution(ax, pred, pred_label, true_label, num_classes):\n",
    "    ax.grid(False)\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "    thisplot = ax.bar(range(num_classes), pred, color=\"#777777\")\n",
    "\n",
    "    thisplot[pred_label].set_color(\"red\")\n",
    "    thisplot[true_label].set_color(\"blue\")\n",
    "\n",
    "def plots_result(info_iter,n,num_classes, title = \"Predict Analysis\"):\n",
    "    \"\"\"\n",
    "    show how to predict\n",
    "    \n",
    "    Args:\n",
    "        search_information_iter : information iter\n",
    "        n : grid space\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    preds = []\n",
    "\n",
    "    for _ in range(n*n):\n",
    "        search = next(search_information_iter)\n",
    "        images.append(search[0])\n",
    "        labels.append(search[1])\n",
    "        preds.append(search[2])\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)       \n",
    "\n",
    "    preds = softmax(preds, axis = 1)\n",
    "    \n",
    "    num_rows = num_cols = int(len(images) ** 0.5)\n",
    "#     print(\"num_rows\", num_rows)\n",
    "#     print(\"len(images) ** 0.5\", len(images) ** 0.5)\n",
    "#     print(\"len(images)\", len(images))\n",
    "    num_images = num_rows * num_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols * 2, figsize=(36, 18))\n",
    "    fig.suptitle(title, fontsize=54)\n",
    "\n",
    "    plt.setp(axes, xticks=[], yticks=[])\n",
    "    \n",
    "    for idx in range(num_images):\n",
    "        image, pred, label = images[idx], preds[idx], labels[idx]\n",
    "\n",
    "        num_row = idx // num_rows\n",
    "        num_col = idx % num_cols\n",
    "\n",
    "        pred_label = np.argmax(pred)\n",
    "        true_label = label\n",
    "\n",
    "        _log_plots_image(\n",
    "            axes[num_row][num_col * 2], image, pred, pred_label, true_label, num_classes\n",
    "        )\n",
    "\n",
    "        _log_plots_distribution(\n",
    "            axes[num_row][num_col * 2 + 1], pred, pred_label, true_label, num_classes\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plots_result(search_information_iter, 4 ,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    x = tensor - tensor.min()\n",
    "    x = x / (x.max() + 1e-9)\n",
    "    return x\n",
    "\n",
    "def draw_border(image_np, color):\n",
    "    color = np.asarray(color)\n",
    "    s = image_np.shape\n",
    "    image_np = image_np.copy()\n",
    "    image_np[0:5, :, :] = color[np.newaxis, np.newaxis, :]\n",
    "    image_np[:, 0:5, :] = color[np.newaxis, np.newaxis, :]\n",
    "    image_np[s[0]-5:s[0], :, :] = color[np.newaxis, np.newaxis, :]\n",
    "    image_np[:, s[0]-5:s[0], :] = color[np.newaxis, np.newaxis, :]\n",
    "    return image_np\n",
    "\n",
    "def show_image(image, title=None):\n",
    "    np_img = image_tensor_to_numpy(image)\n",
    "    if len(np_img.shape) > 3:\n",
    "        np_img = np_img[0]\n",
    "    np_img = normalize(np_img)\n",
    "    \n",
    "    # plot \n",
    "    np_img = np_img.squeeze()\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(np_img)\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def show_images(image_list):\n",
    "    for l in image_list:\n",
    "        f, axarr = plt.subplots(1,len(l))\n",
    "    for i,img in enumerate(l):\n",
    "        np_img = image_tensor_to_numpy(img)\n",
    "        if len(np_img.shape) > 3:\n",
    "            np_img = np_img[0]\n",
    "        np_img = normalize(np_img)\n",
    "        \n",
    "        np_img = np_img.squeeze()\n",
    "        axarr[i].imshow(np_img)\n",
    "        axarr[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
